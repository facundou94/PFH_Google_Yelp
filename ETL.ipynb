{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NO SE PUEDE MOSTRAR](Imagenes/baner2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para instalar/actualizar paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el comando para instalar/actualizar paquetes\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import gdown\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import ast\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from sqlalchemy import create_engine, Column, String, Integer, Table, MetaData, text\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Archivos Inmobiliaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentamos estos datos de una inmobiliaria cuyo caso de implementación del sistema FindEden fué un éxito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Archivos_Inmobiliaria/script_sql_genera_csv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de Archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Metadata - Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs de los archivos de Google Drive\n",
    "file_links = [\n",
    "    'https://drive.google.com/file/d/1OnyhmyG8xzdn4XU9LYcnwzBseB1_rChS', \n",
    "    'https://drive.google.com/file/d/15D_5EkxqPP0XJb5I5bYI8b1wQV7B2fx_', \n",
    "    'https://drive.google.com/file/d/1fDBVCmf4JA7gkIyjpv5mHEMySb19C-vz', \n",
    "    'https://drive.google.com/file/d/1Mj2oUZy5gGznhthcUGi8_sgKhBwypE74', \n",
    "    'https://drive.google.com/file/d/1IXok40Zp61CGwFDgyvLUwV02c4BWGrjj',\n",
    "    'https://drive.google.com/file/d/1UmsN_ZOFQqVl7W9SbnxHkSQavo1_Iwqx', \n",
    "    'https://drive.google.com/file/d/1KfQBhJlnuziKjf-9haQGaiPtCPnUUDla', \n",
    "    'https://drive.google.com/file/d/1ebTUx2klGy7L9lGlZl3GCPXxSwSD55vX', \n",
    "    'https://drive.google.com/file/d/1td6twU60LAS-z5mB0MeSJEpGhH7jcGKm', \n",
    "    'https://drive.google.com/file/d/1NQgHgNm9PV8MSiOXNoQ2UkIF9e5AdLk7', \n",
    "    'https://drive.google.com/file/d/1GYwWfH7EvWMZn14vQRNr5CjEely4eWrB'\n",
    "]\n",
    "\n",
    "# Nombres de los archivos locales (presumiendo que siguen el patrón 1.json, 2.json, ..., 11.json)\n",
    "file_names = [f'{i}.json' for i in range(1, len(file_links) + 1)]\n",
    "\n",
    "# Crear la carpeta MetadataGoogle si no existe\n",
    "output_dir = 'datasets/MetadataGoogle'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Inicializar una lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y leer cada archivo JSON\n",
    "for file_link, file_name in zip(file_links, file_names):\n",
    "    try:\n",
    "        # Ruta completa del archivo\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        # Verificar si el archivo ya está descargado\n",
    "        if not os.path.exists(file_path):\n",
    "            # Obtener el ID del archivo desde el enlace\n",
    "            file_id = file_link.split('/d/')[1].split('/')[0]\n",
    "            download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "            \n",
    "            # Descargar el archivo\n",
    "            gdown.download(download_url, file_path, quiet=False)\n",
    "        \n",
    "        # Leer el archivo JSON en un DataFrame\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            first_char = file.read(1)\n",
    "            if not first_char:\n",
    "                raise ValueError(f\"El archivo {file_name} está vacío.\")\n",
    "            file.seek(0)\n",
    "            df = pd.read_json(file, lines=True)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo {file_name}: {e}\")\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            \n",
    "df_metadatosCA = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Eliminar el DataFrame original para liberar memoria\n",
    "del dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Eliminar duplicados y Filtrar por Estado California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código combina varios DataFrames, filtra los datos por el estado de California y luego limpia el DataFrame resultante para que tenga un índice continuo y no tenga la columna de índice antigua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados basados en la columna 'gmap_id'\n",
    "df_metadatosCA.drop_duplicates(subset=['gmap_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por el estado de California (CA)\n",
    "df_metadatosCA['estado'] = df_metadatosCA['address'].str.extract(r', ([A-Z]{2}) \\d{5}')\n",
    "df_metadatosCA = df_metadatosCA[df_metadatosCA['estado'] == 'CA']\n",
    "\n",
    "# Resetear índice y eliminar la columna de índice antigua\n",
    "df_metadatosCA.reset_index(inplace=True)\n",
    "df_metadatosCA.drop('index', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b - Extraer Ciudad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código de Python está diseñado para extraer la ciudad de una columna de direcciones en un DataFrame de Pandas llamado df_metadatosCA.\n",
    "\n",
    "Este código toma un DataFrame con direcciones y crea una nueva columna que contiene los nombres de las ciudades extraídas. Se basa en una expresión regular para identificar y extraer el nombre de la ciudad según un formato de dirección común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer la ciudad y colocarla en una nueva columna\n",
    "def extract_city(address):\n",
    "    match = re.search(r',\\s*([^,]+),\\s*[A-Z]{2}\\s*\\d{5}', address)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# Aplicar la función a la columna 'address' y crear la columna 'city'\n",
    "df_metadatosCA['city'] = df_metadatosCA['address'].apply(extract_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c - Horas de Atención"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script de Python está diseñado para analizar horarios de apertura y cierre de negocios y calcular las horas diurnas y nocturnas que están abiertos. \n",
    "\n",
    "Estas líneas usan la función apply para aplicar las funciones calculate_day_hours y calculate_night_hours a cada fila de la columna \"hours\" del DataFrame df_metadatosCA. El resultado de cada función se guarda en una nueva columna con el nombre correspondiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para asegurarse de que el tiempo esté en el formato \"HH:MMAM/PM\"\n",
    "def ensure_time_format(time_str):\n",
    "    if '–' in time_str:\n",
    "        parts = time_str.split('–')\n",
    "        parts = [ensure_time_format(part) for part in parts]\n",
    "        return '–'.join(parts)\n",
    "    try:\n",
    "        if ':' not in time_str:\n",
    "            time_obj = pd.to_datetime(time_str, format='%I%p', errors='coerce')\n",
    "        else:\n",
    "            time_obj = pd.to_datetime(time_str, format='%I:%M%p', errors='coerce')\n",
    "        if time_obj is not pd.NaT:\n",
    "            return time_obj.strftime('%I:%M%p')\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting time: {time_str}, error: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las horas diurnas (8 AM - 10 PM)\n",
    "def calculate_day_hours(hours_array):\n",
    "    total_day_hours = 0\n",
    "    if hours_array is not None and isinstance(hours_array, np.ndarray):\n",
    "        for entry in hours_array:\n",
    "            if isinstance(entry, np.ndarray) and len(entry) == 2:\n",
    "                day, hours = entry\n",
    "                if 'Closed' in hours:\n",
    "                    continue\n",
    "                if '–' in hours:\n",
    "                    open_time, close_time = hours.split('–')\n",
    "                    open_time = ensure_time_format(open_time)\n",
    "                    close_time = ensure_time_format(close_time)\n",
    "                    \n",
    "                    if open_time and close_time:\n",
    "                        open_hour = pd.to_datetime(open_time, format='%I:%M%p').hour\n",
    "                        close_hour = pd.to_datetime(close_time, format='%I:%M%p').hour\n",
    "\n",
    "                        if open_hour < 8:\n",
    "                            open_hour = 8\n",
    "                        if close_hour > 22:\n",
    "                            close_hour = 22\n",
    "\n",
    "                        if close_hour < open_hour:\n",
    "                            close_hour += 24  # Para manejar el cambio de día\n",
    "\n",
    "                        total_day_hours += max(0, close_hour - open_hour)\n",
    "    return total_day_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las horas nocturnas (10 PM - 8 AM)\n",
    "def calculate_night_hours(hours_array):\n",
    "    total_night_hours = 0\n",
    "    if hours_array is not None and isinstance(hours_array, np.ndarray):\n",
    "        for entry in hours_array:\n",
    "            if isinstance(entry, np.ndarray) and len(entry) == 2:\n",
    "                day, hours = entry\n",
    "                if 'Closed' in hours:\n",
    "                    continue\n",
    "                if '–' in hours:\n",
    "                    open_time, close_time = hours.split('–')\n",
    "                    open_time = ensure_time_format(open_time)\n",
    "                    close_time = ensure_time_format(close_time)\n",
    "\n",
    "                    if open_time and close_time:\n",
    "                        open_hour = pd.to_datetime(open_time, format='%I:%M%p').hour\n",
    "                        close_hour = pd.to_datetime(close_time, format='%I:%M%p').hour\n",
    "\n",
    "                        if close_hour < open_hour:\n",
    "                            close_hour += 24  # Para manejar el cambio de día\n",
    "\n",
    "                        night_hours = 0\n",
    "                        if open_hour < 8:\n",
    "                            night_hours += min(8, close_hour) - open_hour\n",
    "                        if close_hour > 22:\n",
    "                            night_hours += close_hour - 22\n",
    "\n",
    "                        total_night_hours += max(0, night_hours)\n",
    "    return total_night_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar las funciones al DataFrame\n",
    "df_metadatosCA['Hours_day'] = df_metadatosCA['hours'].apply(calculate_day_hours)\n",
    "df_metadatosCA['Hours_night'] = df_metadatosCA['hours'].apply(calculate_night_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d - Contabilizar Categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código de Python está diseñado para analizar las categorías de negocios en un DataFrame llamado df_metadatosCA y contar cuántas veces aparece cada categoría. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expandir las listas en filas individuales\n",
    "categorias_expandidas = df_metadatosCA['category'].explode()\n",
    "\n",
    "# Contar las ocurrencias de cada categoría y convertir a DataFrame\n",
    "conteo_categorias = categorias_expandidas.value_counts().reset_index()\n",
    "\n",
    "# Renombrar las columnas para mayor claridad\n",
    "conteo_categorias.columns = ['Categoria', 'Frecuencia']\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(conteo_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categorias = len(conteo_categorias)\n",
    "print(f\"La Serie tiene {num_categorias} categorías únicas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la serie que ya no se usa\n",
    "del categorias_expandidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e -Explotar la columna MISC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este código de Python está diseñado para tomar un DataFrame llamado df_metadatosCA que tiene una columna llamada 'MISC' que contiene diccionarios, y expandir esos diccionarios en nuevas columnas en el DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer y expandir los diccionarios en nuevas columnas\n",
    "def expand_misc_column(misc_dict):\n",
    "    if pd.isna(misc_dict):\n",
    "        return pd.Series()\n",
    "    expanded = {}\n",
    "    for key, value in misc_dict.items():\n",
    "        if value is not None and isinstance(value, np.ndarray):\n",
    "            expanded[key] = ', '.join(value)\n",
    "        else:\n",
    "            expanded[key] = value\n",
    "    return pd.Series(expanded)\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "expanded_df = df_metadatosCA['MISC'].apply(expand_misc_column)\n",
    "\n",
    "# Unir el DataFrame original con el DataFrame expandido\n",
    "df_metadatosCA = pd.concat([df_metadatosCA, expanded_df], axis=1)\n",
    "\n",
    "#Eliminar la columna MISC que ya no se usa\n",
    "df_metadatosCA.drop(columns='MISC', inplace=True)\n",
    "\n",
    "del expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código filtra el conjunto de datos df_reviewsGoogle para obtener solo las reseñas que corresponden a los negocios que están en la lista \"negocios\". Luego, crea un nuevo conjunto de datos llamado df_reviewsGoogle_ML que contiene solo las columnas \"user_id\", \"time\", \"rating\" y \"gmap_id\" de las reseñas filtradas.\n",
    "\n",
    "¿Para qué se utiliza este código?\n",
    "\n",
    "Este código parece ser un paso inicial para preparar los datos para un modelo de Machine Learning. Al filtrar las reseñas de los negocios que te interesan, estás creando un conjunto de datos específico que puedes usar para entrenar un modelo que prediga algo relacionado con las reseñas, como la calificación promedio de un negocio o la probabilidad de que un usuario deje una reseña positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir ciudad\n",
    "ciudadelegida='Los Angeles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro el listado\n",
    "negocios=df_metadatosCA['gmap_id'][df_metadatosCA['city'] == ciudadelegida]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro por los negocios de la ciudad\n",
    "# Generar el dataframe a exportar\n",
    "metadatos_ML = df_metadatosCA.loc[df_metadatosCA['city'] == ciudadelegida, \n",
    "                           ['address', 'gmap_id', 'latitude', 'longitude',\n",
    "                            'category', 'avg_rating', 'num_of_reviews', 'Hours_day', 'Hours_night']]\n",
    "\n",
    "# Exportar el dataframe\n",
    "metadatos_ML.to_csv('Archivos/metadatos_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Reviews Estados - Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs de los archivos de Google Drive\n",
    "file_links = [\n",
    "    'https://drive.google.com/file/d/13JlGdagtTp4SrUIXu5osayX0f-vmeMz6',\n",
    "    'https://drive.google.com/file/d/1PIruhKSA5gEwk93-jwKdlG_vtwJmBHWV', \n",
    "    'https://drive.google.com/file/d/1JVSi-345m8nt52m2_MPkLULZexbvZUAV', \n",
    "    'https://drive.google.com/file/d/1vYYCtcNcfdRzQpEskb8x-8npZUHj2XY-', \n",
    "    'https://drive.google.com/file/d/1nCyVnhNpfphd26ye3lj9UsWvPTEhik6b', \n",
    "    'https://drive.google.com/file/d/12PR9jUiZLYvjw6BZjwlexgsWmJlMOajN',\n",
    "    'https://drive.google.com/file/d/1Oq1UdTmQ4xFgkaFdx09JXJQ1_pnIk-il', \n",
    "    'https://drive.google.com/file/d/1UwzEftWrssj8Vt0BAf_W9L_TVDGa9JD9', \n",
    "    'https://drive.google.com/file/d/1KsXni6or_cPKovgUaRI_3G4-mRXfqgog', \n",
    "    'https://drive.google.com/file/d/1fK2kTLDqlUcDt6bKa20W5LvOmrfemDrg', \n",
    "    'https://drive.google.com/file/d/1rMz_y1cqa8IBwv1K6K34fAXB2qoRjmEG', \n",
    "    'https://drive.google.com/file/d/1t59IfitryIsy8-F9NL9J6M75UElQO0i9',\n",
    "    'https://drive.google.com/file/d/17VtmF8701j3Tk-tdHeRrXDzj32UyWFVh',\n",
    "    'https://drive.google.com/file/d/1zoN6XJV220ofRKVlM8DP--FriL_OcZEP',\n",
    "    'https://drive.google.com/file/d/1HUVCM9uOrXhoOzoSD9NqhHJ1PHrLEhBC',\n",
    "    'https://drive.google.com/file/d/1sqp0YG4OHVUoA0gWrgwg1wXpdOlF5RfD',\n",
    "    'https://drive.google.com/file/d/1SPDbJPTxKV1QqMcRNsHIhV7EZBLtRCWf',\n",
    "    'https://drive.google.com/file/d/1_Ik1uLilfLe0MEb1Gia-t9SpE1Wwdwnm'\n",
    "]\n",
    "\n",
    "# Nombre de la carpeta que quieres crear\n",
    "carpeta_destino = 'datasets/ReviewsEstadosGoogle'\n",
    "\n",
    "# Verificar si la carpeta existe\n",
    "if not os.path.exists(carpeta_destino):\n",
    "    # Crear la carpeta si no existe\n",
    "    os.makedirs(carpeta_destino)\n",
    "    print(f\"Se ha creado la carpeta: {carpeta_destino}\")\n",
    "else:\n",
    "    print(f\"La carpeta {carpeta_destino} ya existe.\")\n",
    "    \n",
    "# Nombres de los archivos locales (presumiendo que siguen el patrón 1.json, 2.json, ..., 11.json)\n",
    "file_names = [f'datasets/ReviewsEstadosGoogle/{i}.json' for i in range(1, len(file_links) + 1)]\n",
    "\n",
    "# Inicializar una lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y leer cada archivo JSON si no está descargado previamente\n",
    "for file_link, file_name in zip(file_links, file_names):\n",
    "    try:\n",
    "        # Verificar si el archivo ya está descargado\n",
    "        if not os.path.exists(file_name):\n",
    "            # Obtener el ID del archivo desde el enlace\n",
    "            file_id = file_link.split('/d/')[1].split('/')[0]\n",
    "            download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "            \n",
    "            # Descargar el archivo\n",
    "            gdown.download(download_url, file_name, quiet=False)\n",
    "            \n",
    "            # Verificar si el archivo descargado es un JSON válido\n",
    "            with open(file_name, 'r', encoding='utf-8') as file:\n",
    "                first_char = file.read(1)\n",
    "                if not first_char:\n",
    "                    raise ValueError(f\"El archivo {file_name} está vacío.\")\n",
    "                file.seek(0)\n",
    "            \n",
    "        # Leer el archivo JSON en un DataFrame\n",
    "        df = pd.read_json(file_name, lines=True)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo {file_name}: {e}\")\n",
    "\n",
    "del df\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_reviewsGoogle = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Eliminación de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este código elimina las filas duplicadas del DataFrame df_reviewsGoogle solo si las filas tienen los mismos valores en las columnas 'user_id', 'time' y 'gmap_id'. Esto es útil para asegurar que cada combinación única de estas tres columnas represente una reseña única."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewsGoogle.drop_duplicates(subset=['user_id', 'time', 'gmap_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b - Tratamiento de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código crea una nueva columna 'has_text' en el DataFrame df_reviewsGoogle. Esta columna tendrá un valor de 1 si la columna 'text' contiene texto real (no está vacía o solo espacios en blanco) y 0 si no contiene texto real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si contiene texto\n",
    "df_reviewsGoogle['has_text'] = df_reviewsGoogle['text'].apply(lambda x: 1 if isinstance(x, str) and len(x.strip()) > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código crea una nueva columna 'num_pics' en el DataFrame df_reviewsGoogle. Esta columna tendrá un valor que representa la cantidad de elementos en la lista que se encuentra en la columna 'pics' para cada fila. Si la columna 'pics' no contiene una lista, la columna 'num_pics' tendrá un valor de 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de fotos\n",
    "df_reviewsGoogle['num_pics'] = df_reviewsGoogle['pics'].apply(lambda x: len(x) if isinstance(x, list) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código crea una nueva columna 'has_resp' en el DataFrame df_reviewsGoogle. Esta columna tendrá un valor de 1 si la columna 'resp' contiene un diccionario no vacío y 0 si no lo contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tiene respuesta\n",
    "df_reviewsGoogle['has_resp'] = df_reviewsGoogle['resp'].apply(lambda x: 1 if isinstance(x, dict) and len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c - Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro por los negocios de la ciudad\n",
    "df_reviewsGoogle_ML = df_reviewsGoogle[df_reviewsGoogle['gmap_id'].isin(negocios)][['user_id', 'time', 'rating', 'gmap_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esportar a un csv\n",
    "df_reviewsGoogle_ML.to_csv('Archivos/reviewsGoogle_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Archivos para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga archivos\n",
    "df_metadatos = pd.read_csv(\"Archivos/metadatos_ML.csv\") # 18776 filas x 9 columnas\n",
    "df_reviewsGoogle = pd.read_csv(\"Archivos/reviewsGoogle_ML.csv\") # 154586 reviews con  gmap_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tratamiento de categorías generales\n",
    "\n",
    "Se estableceran las siguientes categorías:\n",
    "\n",
    "    - Auto\n",
    "    - Beauty\n",
    "    - Clothes\n",
    "    - Health\n",
    "    - Home\n",
    "    - Food\n",
    "    - Entertainment\n",
    "    - Education\n",
    "    - Services\n",
    "    - Sports\n",
    "    - Technology\n",
    "    - Religion\n",
    "    - Stores\n",
    "    - Buildings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_category(category):\n",
    "    auto_keywords = [\"auto\", \"car\", \"gas station\", \"parking\", \"vehicle\", \"tire\"]\n",
    "    beauty_keywords = [\"beauty\", \"hair\", \"nail\", \"cosmetic\", \"spa\", \"salon\", \"massage\"]\n",
    "    clothes_keywords = [\"clothing\", \"shoe\", \"boutique\", \"fashion\"]\n",
    "    health_keywords = [\"hospital\", \"clinic\", \"doctor\", \"pharmacy\", \"dental\", \"health\", \"medical\", \"nurse\", \"vet\", \"veterinary\",'dentist']\n",
    "    home_keywords = [\"home\", \"furniture\", \"garden\", \"real estate\", \"property\", \"plumber\", \"electrician\", \"construction\",'laundromat',\"dry cleaner\"]\n",
    "    food_keywords = [\"restaurant\", \"cafe\", \"bakery\", \"grocery\", \"supermarket\", \"food\", \"bar\", \"pub\"]\n",
    "    entertainment_keywords = [\"theater\", \"cinema\", \"museum\", \"park\", \"zoo\", \"amusement\", \"casino\",'art gallery']\n",
    "    education_keywords = [\"school\", \"university\", \"college\", \"library\", \"education\", \"learning\", \"academy\"]\n",
    "    services_keywords = [\"bank\", \"insurance\", \"consulting\", \"lawyer\", \"attorney\", \"service\", \"repair\", \"maintenance\", \"laundry\", \"post office\"]\n",
    "    sports_keywords = [\"gym\", \"fitness\", \"sport\", \"stadium\", \"arena\", \"athletic\"]\n",
    "    technology_keywords = [\"it\", \"tech\", \"technology\", \"computer\", \"software\", \"hardware\", \"electronics\", \"telecom\"]\n",
    "    religion_keywords = [\"synagogue\", \"church\", \"buddhist\", \"mosque\",\"religious\"]\n",
    "    stores_keywords = ['liquor store','convenience store','Store','store','coffee shop','shopping mall','cell phone store','florist',\"fabric store\",\"shop\",'jeweler']\n",
    "    buildings_keywords = ['corporate office','apartment','condominium','hotel','store','coffee shop','shopping mall','cell phone store','florist',\"fabric store\",\"shop\"]\n",
    "\n",
    "    if isinstance(category, str):\n",
    "        \n",
    "        # Convertir la categoría a minúsculas para la comparación\n",
    "        category_lower = category.lower()\n",
    "\n",
    "        if any(keyword in category_lower for keyword in auto_keywords):\n",
    "            return \"Auto\"\n",
    "        if any(keyword in category_lower for keyword in beauty_keywords):\n",
    "            return \"Beauty\"\n",
    "        if any(keyword in category_lower for keyword in clothes_keywords):\n",
    "            return \"Clothes\"\n",
    "        if any(keyword in category_lower for keyword in health_keywords):\n",
    "            return \"Health\"\n",
    "        if any(keyword in category_lower for keyword in home_keywords):\n",
    "            return \"Home\"\n",
    "        if any(keyword in category_lower for keyword in food_keywords):\n",
    "            return \"Food\"\n",
    "        if any(keyword in category_lower for keyword in entertainment_keywords):\n",
    "            return \"Entertainment\"\n",
    "        if any(keyword in category_lower for keyword in education_keywords):\n",
    "            return \"Education\"\n",
    "        if any(keyword in category_lower for keyword in services_keywords):\n",
    "            return \"Services\"\n",
    "        if any(keyword in category_lower for keyword in sports_keywords):\n",
    "            return \"Sports\"\n",
    "        if any(keyword in category_lower for keyword in technology_keywords):\n",
    "            return \"Technology\"\n",
    "        if any(keyword in category_lower for keyword in religion_keywords):\n",
    "            return \"Religion\"\n",
    "        if any(keyword in category_lower for keyword in stores_keywords):\n",
    "            return \"Stores\"\n",
    "        if any(keyword in category_lower for keyword in buildings_keywords):\n",
    "            return \"Buildings\"\n",
    "        \n",
    "        return \"Other\"\n",
    "    \n",
    "    return \"Other\"\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df_metadatos['general_category'] = df_metadatos['category'].apply(generalize_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contabilizamos la Frecuencia absoluta de las categorías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadatos[\"general_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame donde general_category es igual a \"Other\"\n",
    "filtered_df = df_metadatos[df_metadatos[\"general_category\"] == \"Other\"]\n",
    "\n",
    "# Contar los valores de la columna \"category\" en el DataFrame filtrado\n",
    "category_counts = filtered_df[\"category\"].value_counts()\n",
    "\n",
    "# Mostrar los resultados\n",
    "category_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tratamiento de categorías de locales\n",
    "\n",
    "Se estableceran las siguientes categorías de elección con sus sub-categorías:\n",
    "\n",
    "    Restaurant: - Comida asiática\n",
    "                - Comida latinoamericana\n",
    "                - Comida europea\n",
    "                - Comida norteamericana y fast food\n",
    "                - Comida vegana y vegetariana\n",
    "\n",
    "    Religion:   - Protestanismo (cat 1)\n",
    "                - Catolisismo (cat 2)\n",
    "                - Judaísmo (cat 3)\n",
    "                - Budismo (cat 4)\n",
    "                - Islam (cat 5)\n",
    "    Recreation:\n",
    "                - Arte, música, teatro, cine, bibliotecas (cat 1)\n",
    "                - Clubes nocturnos (cat 2)\n",
    "                - Salas de Bowling, pool, dardos, casino (cat 3)\n",
    "\n",
    "Se establece la categoría general de bienestar:\n",
    "\n",
    "    Bienestar: - Lugares públicos de esparcimiento\n",
    "               - Centros asistenciales de salud\n",
    "               - Estaciones policiales\n",
    "               - Estaciones de bomberos\n",
    "               - Gimnasios y centros de actividad física\n",
    "               - Farmacias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para seleccionar categorías de restaurants\n",
    "\n",
    "# Función para verificar y asignar res_asian\n",
    "def categorize_res_asian(categories):\n",
    "    if isinstance(categories, str):\n",
    "        if any(keyword in categories for keyword in [\"Asian restaurant\", \"Vietnamese restaurant\",\"Chinese restaurant\", \n",
    "                                                     \"Sushi restaurant\", \"Ramen restaurant\", \"Korean restaurant\", \n",
    "                                                     \"Japanese restaurant\",\"Sushi takeaway\",\"Chinese takeaway\",\n",
    "                                                     \"Asian fusion restaurant\", \"Southeast Asian restaurant\", \"South Asian restaurant\",\n",
    "                                                     \"Thai restaurant\", \"Korean barbecue restaurant\"]):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Función para verificar y asignar res_latin\n",
    "def categorize_res_latin(categories):\n",
    "    if isinstance(categories, str):\n",
    "        if any(keyword in categories for keyword in [\"Mexican restaurant\", \"Tex-Mex restaurant\",\"Mexican torta restaurant\", \n",
    "                                                     \"Taco restaurant\", \"Burrito restaurant\", \"Salvadoran restaurant\", \n",
    "                                                     \"South American restaurant\",\"Latin American restaurant\",\"Nuevo Latino restaurant\",\n",
    "                                                     \"Pan-Latin restaurant\", \"Argentinian restaurant\", \"Brazilian restaurant\",\n",
    "                                                     \"Colombian restaurant\", \"Venezuelan restaurant\", \"Peruvian restaurant\",\n",
    "                                                     \"Central American restaurant\"]):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Función para verificar y asignar res_euro\n",
    "def categorize_res_euro(categories):\n",
    "    if isinstance(categories, str):\n",
    "        if any(keyword in categories for keyword in [\"Greek restaurant\", \"Italian restaurant\", \"Northern Italian restaurant\", \n",
    "                                                     \"Southern Italian restaurant\", \"Spanish restaurant\", \"Mediterranean restaurant\", \n",
    "                                                     \"French restaurant\",\"Modern French restaurant\",\"Haute French restaurant\",\n",
    "                                                     \"French steakhouse restaurant\", \"German restaurant\", \"British restaurant\",\n",
    "                                                     \"Russian restaurant\", \"European restaurant\", \"Modern European restaurant\"]):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Función para verificar y asignar res_latin\n",
    "def categorize_res_fast(categories):\n",
    "    if isinstance(categories, str):\n",
    "        if any(keyword in categories for keyword in [\"Fast food restaurant\", \"Hamburguer restaurant\", \"American restaurant\", \n",
    "                                                     \"Sandwich shop\", \"Pizza restaurant\", \"Pizza delivery\", \n",
    "                                                     \"Pizza takeout\",\"Pizza takeaway\",\"Hot dog restaurant\",\n",
    "                                                     \"Hot dog stand\", \"Chicken wings restaurant\", \"Chicken restaurant\",\n",
    "                                                     \"Fried Chicken takeaway\", \"Barbecue restaurant\", \"Salad shop\"]):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Función para verificar y asignar res_latin\n",
    "def categorize_res_vegan(categories):\n",
    "    if isinstance(categories, str):\n",
    "        if any(keyword in categories for keyword in [\"Vegan restaurant\", \"Salad shop\", \"Vegetarian restaurant\", \n",
    "                                                     \"Vegetarian cafe and deli\"]):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a cada fila\n",
    "df_metadatos[\"res_asian\"] = df_metadatos[\"category\"].apply(categorize_res_asian)\n",
    "df_metadatos[\"res_latin\"] = df_metadatos[\"category\"].apply(categorize_res_latin)\n",
    "df_metadatos[\"res_euro\"] = df_metadatos[\"category\"].apply(categorize_res_euro)\n",
    "df_metadatos[\"res_fast\"] = df_metadatos[\"category\"].apply(categorize_res_fast)\n",
    "df_metadatos[\"res_vegan\"] = df_metadatos[\"category\"].apply(categorize_res_vegan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para seleccionar categorías de religion\n",
    "\n",
    "# Función para verificar y asignar rel_pro\n",
    "def categorize_rel(categories):\n",
    "    if isinstance(categories, str):\n",
    "        \n",
    "        if any(keyword in categories for keyword in [\"Gospel church\", \"Reformed church\", \"Foursquare church\",\n",
    "                                                     \"Church of the Nazarene\", \"Apostolic church\", \"Evangelical church\", \n",
    "                                                     \"Assemblies of God church\", \"Calvary Chapel church\", \"Pentecostal church\", \n",
    "                                                     \"Methodist church\", \"Church of Christ\", \"Non-denominational church\", \n",
    "                                                     \"Presbyterian church\", \"Lutheran church\", \"Baptist church\", \n",
    "                                                     \"Christian church\", \"Protestant church\"]):\n",
    "            return 1\n",
    "        \n",
    "        if any(keyword in categories for keyword in [\"Catholic church\", \"Cathedral\",\"Catholic Cathedral\"]):\n",
    "            return 2\n",
    "\n",
    "        if any(keyword in categories for keyword in [\"Synagogue\", \"Orthodox synagogue\",\"Reform synagogue\",\n",
    "                                                     \"Conservative synagogue\",\"Messianic synagogue\"]):\n",
    "            return 3\n",
    "\n",
    "        if any(keyword in categories for keyword in [\"Buddhist temple\"]):\n",
    "            return 4\n",
    "\n",
    "        if any(keyword in categories for keyword in [\"Mosque\"]):\n",
    "            return 5\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a cada fila\n",
    "df_metadatos[\"religion\"] = df_metadatos[\"category\"].apply(categorize_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para seleccionar categorías de recreacion\n",
    "\n",
    "# Función para verificar y asignar rel_pro\n",
    "def categorize_rec(categories):\n",
    "    if isinstance(categories, str):\n",
    "        \n",
    "        if any(keyword in categories for keyword in [\"Performing arts theater\", \"Movie theater\", \"Amphitheater\",\n",
    "                                                     \"Drama theater\", \"Outdoor movie theater\", \"Drive-in movie theater\", \n",
    "                                                     \"Ballet theater\", \"Live music venue\", \"Live music bar\", \n",
    "                                                     \"Musical club\", \"Public library\"]):\n",
    "            return 1\n",
    "        \n",
    "        if any(keyword in categories for keyword in [\"Night club\", \"Disco club\",\"Dance hall\", \n",
    "                                                     \"Pub\", \"Brewpub\", \"Gastropub\", \"Irish pub\"]):\n",
    "            return 2\n",
    "\n",
    "        if any(keyword in categories for keyword in [\"Bowling alley\", \"Sports bar\",\"Pool hall\",\n",
    "                                                     \"Pool billard club\",\"Video arcade\", \"Dart bar\",\n",
    "                                                     \"Casino\"]):\n",
    "            return 3\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a cada fila\n",
    "df_metadatos[\"recreation\"] = df_metadatos[\"category\"].apply(categorize_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para seleccionar categorías de bienestar\n",
    "\n",
    "# Función para verificar y asignar bien\n",
    "def categorize_bien(categories):\n",
    "    if isinstance(categories, str):\n",
    "        if any(keyword in categories for keyword in [\"Public beach\", \"public swimming pool\", \"Public educational institution\",\n",
    "                                                      \"Medical center\", \"Medical clinic\", \"Hospital\",\n",
    "                                                      \"General hospital\", \"Fire station\", \"Police department\",\n",
    "                                                      \"Police station\", \"State police\", \"Civil police\",\n",
    "                                                      \"Park\", \"Gym\", \"Pharmacy\", \"Fitness center\"]):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a cada fila\n",
    "df_metadatos[\"bienestar\"] = df_metadatos[\"category\"].apply(categorize_bien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del DataFrame\n",
    "df_metadatos[\"recreation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Filtrado de locales que aporten información al algoritmo y chequeo con otras fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a verificar\n",
    "columns_to_check = ['res_asian', 'res_euro', 'res_latin', 'res_fast', 'res_vegan', 'religion', 'recreation', 'bienestar']\n",
    "\n",
    "# Filtrar el DataFrame\n",
    "df_metadatos_filtered = df_metadatos[df_metadatos[columns_to_check].any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadatos_filtered.info() # De 18776 a 2814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los \"gmap_id\" únicos de df_metadatos_filtered\n",
    "gmap_ids_filtered = df_metadatos_filtered['gmap_id'].unique()\n",
    "\n",
    "# Filtrar df_reviewsGoogle\n",
    "df_reviewsGoogle_filtered = df_reviewsGoogle[df_reviewsGoogle['gmap_id'].isin(gmap_ids_filtered)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewsGoogle_filtered.info() # De 154586 a 52407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewsGoogle_filtered['date'] = pd.to_datetime(df_reviewsGoogle['time'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tratamiento de usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la cantidad de reseñas por user_id\n",
    "reviews_count = df_reviewsGoogle['user_id'].value_counts()\n",
    "\n",
    "# Filtrar los usuarios con más de 7 reseñas\n",
    "filtered_reviews_count = reviews_count[reviews_count > 3]\n",
    "\n",
    "# Limitar la cantidad de reseñas a un máximo de 30 para agrupar en el histograma\n",
    "filtered_reviews_count_clipped = filtered_reviews_count.clip(upper=30)\n",
    "\n",
    "# Crear el histograma\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.hist(filtered_reviews_count_clipped, bins=list(range(4, 31)) + [31], edgecolor='black', align='left')\n",
    "plt.title('Histograma de la Cantidad de Reseñas por Usuario (Al menos 4 reseñas)')\n",
    "plt.xlabel('Cantidad de Reseñas')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xticks(list(range(4, 31)) + [30])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Añadir una leyenda personalizada\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "custom_labels = list(range(4, 30)) + ['30+']\n",
    "plt.legend(handles, custom_labels, title=\"Cantidad de Reseñas\")\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge para añadir avg_rating al df_reviewsGoogle\n",
    "df_reviewsGoogle = df_reviewsGoogle.merge(df_metadatos[['gmap_id', 'avg_rating', 'general_category']], on='gmap_id', how='left')\n",
    "\n",
    "# Renombrar la columna avg_rating a business_avg_rating\n",
    "df_reviewsGoogle.rename(columns={'avg_rating': 'business_avg_rating'}, inplace=True)\n",
    "\n",
    "# Crear la columna dif_rating\n",
    "df_reviewsGoogle['dif_rating'] = df_reviewsGoogle['business_avg_rating'] - df_reviewsGoogle['rating']\n",
    "\n",
    "# Calcular la cantidad de reseñas por usuario\n",
    "user_reviews_count = df_reviewsGoogle['user_id'].value_counts().reset_index()\n",
    "user_reviews_count.columns = ['user_id', 'reviews_count']\n",
    "\n",
    "# Calcular la media de dif_rating por usuario\n",
    "user_avg_dif_rating = df_reviewsGoogle.groupby('user_id')['dif_rating'].mean().reset_index()\n",
    "user_avg_dif_rating.columns = ['user_id', 'avg_dif_rating']\n",
    "\n",
    "# Calcular las reseñas por user_id y general_category\n",
    "user_category_reviews = df_reviewsGoogle.groupby(['user_id', 'general_category']).size().reset_index(name='category_reviews')\n",
    "\n",
    "# Pivote de los datos para tener general_category como columnas\n",
    "user_category_pivot = user_category_reviews.pivot(index='user_id', columns='general_category', values='category_reviews').fillna(0).reset_index()\n",
    "\n",
    "# Merge para combinar la cantidad de reseñas y la media de dif_rating por usuario\n",
    "df_user_stats = user_reviews_count.merge(user_avg_dif_rating, on='user_id', how='left')\n",
    "\n",
    "# Filtrar df_user_stats para incluir solo user_id con 8 reseñas o más\n",
    "df_user_stats_filtered = df_user_stats[df_user_stats['reviews_count'] >= 4]\n",
    "\n",
    "# Merge con df_user_stats_filtered para agregar las categorías\n",
    "df_user_stats_filtered = df_user_stats_filtered.merge(user_category_pivot, on='user_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media de dif_rating en valor absoluto por usuario\n",
    "user_avg_dif_modulo = df_reviewsGoogle.groupby('user_id')['dif_rating'].apply(lambda x: x.abs().mean()).reset_index()\n",
    "user_avg_dif_modulo.columns = ['user_id', 'avg_dif_modulo']\n",
    "\n",
    "# Merge para combinar avg_dif_modulo con df_user_stats_filtered\n",
    "df_user_stats_filtered = df_user_stats_filtered.merge(user_avg_dif_modulo, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la lista de categorías\n",
    "categories = ['Auto', 'Beauty', 'Buildings', 'Clothes', 'Education', 'Entertainment', 'Food', 'Health',\n",
    "              'Home', 'Other', 'Religion', 'Services', 'Sports', 'Stores', 'Technology']\n",
    "\n",
    "# Crear la columna sum_category\n",
    "df_user_stats_filtered['sum_category'] = df_user_stats_filtered[categories].apply(lambda x: (x > 0).sum(), axis=1)\n",
    "\n",
    "# Eliminar las columnas de categorías específicas\n",
    "df_user_stats_filtered = df_user_stats_filtered.drop(columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular máximo y mínimo de cada columna en df_user_stats_filtered\n",
    "max_values = df_user_stats_filtered.max()\n",
    "min_values = df_user_stats_filtered.min()\n",
    "\n",
    "print(\"Valores máximos:\")\n",
    "print(max_values)\n",
    "print(\"\\nValores mínimos:\")\n",
    "print(min_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_stats_filtered[\"reviews_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las condiciones y las puntuaciones correspondientes\n",
    "conditions = [\n",
    "    (df_user_stats_filtered['reviews_count'] > 9) & \n",
    "    (df_user_stats_filtered['avg_dif_rating'].between(-0.5, 0.5, inclusive='both')) & \n",
    "    (df_user_stats_filtered['avg_dif_modulo'] <= 1) &\n",
    "    (df_user_stats_filtered['sum_category'] > 6),\n",
    "\n",
    "    (df_user_stats_filtered['reviews_count'] > 9) & \n",
    "    #(df_user_stats_filtered['avg_dif_rating'].between(-0.5, 0.5, inclusive='both')) & \n",
    "    (df_user_stats_filtered['avg_dif_modulo'] <= 1) &\n",
    "    (df_user_stats_filtered['sum_category'] > 6),\n",
    "\n",
    "    #(df_user_stats_filtered['reviews_count'] > 9) &\n",
    "    (df_user_stats_filtered['sum_category'] > 3) &\n",
    "    (df_user_stats_filtered['avg_dif_modulo'] <= 1),\n",
    "\n",
    "    (df_user_stats_filtered['avg_dif_modulo'] <= 1.5),\n",
    "]\n",
    "\n",
    "choices = [5, 4, 3, 2]\n",
    "\n",
    "# Aplicar las condiciones y asignar la columna user_rating\n",
    "df_user_stats_filtered['user_rating'] = np.select(conditions, choices, default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_stats_filtered[\"user_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Creación de base de datos final de locales con usuarios ponderados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el merge para añadir user_rating a df_reviewsGoogle_filtered\n",
    "df_reviewsGoogle_filtered = df_reviewsGoogle_filtered.merge(df_user_stats_filtered[['user_id', 'user_rating']], on='user_id', how='left')\n",
    "\n",
    "# Rellenar los valores faltantes en user_rating con 1\n",
    "df_reviewsGoogle_filtered['user_rating'].fillna(1, inplace=True)\n",
    "\n",
    "# Asegurar que user_rating sea de tipo entero si es necesario\n",
    "df_reviewsGoogle_filtered['user_rating'] = df_reviewsGoogle_filtered['user_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewsGoogle_filtered[\"user_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: Calcular la suma ponderada de ratings y la suma ponderada de las ponderaciones por gmap_id\n",
    "df_reviewsGoogle_filtered['weighted_rating'] = df_reviewsGoogle_filtered['rating'] * df_reviewsGoogle_filtered['user_rating']\n",
    "df_reviewsGoogle_filtered['weight'] = df_reviewsGoogle_filtered['user_rating']\n",
    "\n",
    "# Agrupar por gmap_id y calcular las sumas ponderadas\n",
    "grouped = df_reviewsGoogle_filtered.groupby('gmap_id').agg(\n",
    "    total_weighted_rating=('weighted_rating', 'sum'),\n",
    "    total_weight=('weight', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Paso 3: Calcular avg_rating_correction dividiendo la suma ponderada de ratings entre la suma ponderada de las ponderaciones\n",
    "grouped['avg_rating_correction'] = grouped['total_weighted_rating'] / grouped['total_weight']\n",
    "\n",
    "# Paso 4: Merge de avg_rating_correction con df_metadatos_filtered\n",
    "df_metadatos_filtered = df_metadatos_filtered.merge(grouped[['gmap_id', 'avg_rating_correction']], on='gmap_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadatos_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar los gmap_id únicos en cada DataFrame\n",
    "gmap_ids_reviews = set(df_reviewsGoogle_filtered['gmap_id'])\n",
    "gmap_ids_metadatos = set(df_metadatos_filtered['gmap_id'])\n",
    "\n",
    "# Contar el número de gmap_id únicos en cada DataFrame\n",
    "count_gmap_ids_reviews = len(gmap_ids_reviews)\n",
    "count_gmap_ids_metadatos = len(gmap_ids_metadatos)\n",
    "\n",
    "# Encontrar los gmap_id que están en ambos DataFrames\n",
    "common_gmap_ids = gmap_ids_reviews.intersection(gmap_ids_metadatos)\n",
    "count_common_gmap_ids = len(common_gmap_ids)\n",
    "\n",
    "# Encontrar los gmap_id que faltan en cada DataFrame\n",
    "gmap_ids_missing_in_reviews = gmap_ids_metadatos - gmap_ids_reviews\n",
    "gmap_ids_missing_in_metadatos = gmap_ids_reviews - gmap_ids_metadatos\n",
    "\n",
    "count_gmap_ids_missing_in_reviews = len(gmap_ids_missing_in_reviews)\n",
    "count_gmap_ids_missing_in_metadatos = len(gmap_ids_missing_in_metadatos)\n",
    "\n",
    "# Resultados\n",
    "print(f\"gmap_id únicos en df_reviewsGoogle_filtered: {count_gmap_ids_reviews}\")\n",
    "print(f\"gmap_id únicos en df_metadatos_filtered: {count_gmap_ids_metadatos}\")\n",
    "print(f\"gmap_id comunes en ambos DataFrames: {count_common_gmap_ids}\")\n",
    "print(f\"gmap_id faltantes en df_reviewsGoogle_filtered: {count_gmap_ids_missing_in_reviews}\")\n",
    "print(f\"gmap_id faltantes en df_metadatos_filtered: {count_gmap_ids_missing_in_metadatos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadatos_filtered[[\"avg_rating\",\"avg_rating_correction\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA EN REPOSITORIO LOCAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar df_metadatos_filtered como un archivo CSV\n",
    "df_metadatos_filtered.to_csv('Archivos/locales_LA.csv', index=False)\n",
    "\n",
    "# Guardar df_metadatos_filtered como un archivo CSV\n",
    "df_reviewsGoogle_filtered.to_csv('Archivos/reviews_LA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga (LOAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA EN MYSQL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga es incremental, en caso de no existir las tablas las crea, si los datos a cargar son los mismos que los que estan no se cargan, y si hy datos nuevos sólo carga los nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Script para crear tablas si no existen (crear_tablas.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tabla 'metadatos' ya existe. No es necesario crearla de nuevo.\n",
      "La tabla 'reviewsGoogle' no existe. Creando tabla...\n",
      "La tabla 'reviewsGoogle' ya existe. No es necesario crearla de nuevo.\n",
      "La tabla 'locales_LA' no existe. Creando tabla...\n",
      "La tabla 'locales_LA' ya existe. No es necesario crearla de nuevo.\n",
      "La tabla 'reviews_LA' no existe. Creando tabla...\n",
      "La tabla 'reviews_LA' ya existe. No es necesario crearla de nuevo.\n"
     ]
    }
   ],
   "source": [
    "%run crear_tablas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Script para carga incremental (cargar_incremental.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron nuevos registros para la tabla 'metadatos'.\n",
      "No se encontraron nuevos registros para la tabla 'reviewsGoogle'.\n",
      "No se encontraron nuevos registros para la tabla 'locales_LA'.\n",
      "No se encontraron nuevos registros para la tabla 'reviews_LA'.\n"
     ]
    }
   ],
   "source": [
    "%run cargar_incremental.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Crear ETL local como script de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script ETL.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Cargamos la Información a:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a - GCP BIG QUERY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo metadatos_ML.csv cargado en la tabla findeden.findeden.metadatos_ML\n",
      "Archivo reviewsGoogle_ML.csv cargado en la tabla findeden.findeden.reviewsGoogle_ML\n",
      "Archivo locales_LA.csv cargado en la tabla findeden.findeden.locales_LA\n",
      "Archivo reviews_LA.csv cargado en la tabla findeden.findeden.reviews_LA\n",
      "Archivo Contratos.csv cargado en la tabla findeden.findeden.Contratos\n",
      "Archivo Inquilinos.csv cargado en la tabla findeden.findeden.Inquilinos\n",
      "Archivo Propiedades.csv cargado en la tabla findeden.findeden.Propiedades\n",
      "Archivo Publicaciones_Alquileres.csv cargado en la tabla findeden.findeden.Publicaciones_Alquileres\n"
     ]
    }
   ],
   "source": [
    "%run cloud_up.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generar el archivo requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
