{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\londe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\londe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\londe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "ERROR: No matching distribution found for re\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib numpy re time ast collections gdown ipykernel nbconvert ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import gdown\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import ast\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata  - Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los archivos desde la GoogleDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tamaño:\n",
    "carpeta: 2,76 Gb\n",
    "dataframe 370 Mb\n",
    "csv 2,3 Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IDs de los archivos de Google Drive\n",
    "file_links = [\n",
    "    'https://drive.google.com/file/d/1OnyhmyG8xzdn4XU9LYcnwzBseB1_rChS', \n",
    "    'https://drive.google.com/file/d/15D_5EkxqPP0XJb5I5bYI8b1wQV7B2fx_', \n",
    "    'https://drive.google.com/file/d/1fDBVCmf4JA7gkIyjpv5mHEMySb19C-vz', \n",
    "    'https://drive.google.com/file/d/1Mj2oUZy5gGznhthcUGi8_sgKhBwypE74', \n",
    "    'https://drive.google.com/file/d/1IXok40Zp61CGwFDgyvLUwV02c4BWGrjj',\n",
    "    'https://drive.google.com/file/d/1UmsN_ZOFQqVl7W9SbnxHkSQavo1_Iwqx', \n",
    "    'https://drive.google.com/file/d/1KfQBhJlnuziKjf-9haQGaiPtCPnUUDla', \n",
    "    'https://drive.google.com/file/d/1ebTUx2klGy7L9lGlZl3GCPXxSwSD55vX', \n",
    "    'https://drive.google.com/file/d/1td6twU60LAS-z5mB0MeSJEpGhH7jcGKm', \n",
    "    'https://drive.google.com/file/d/1NQgHgNm9PV8MSiOXNoQ2UkIF9e5AdLk7', \n",
    "    'https://drive.google.com/file/d/1GYwWfH7EvWMZn14vQRNr5CjEely4eWrB'\n",
    "]\n",
    "\n",
    "# Nombres de los archivos locales (presumiendo que siguen el patrón 1.json, 2.json, ..., 11.json)\n",
    "file_names = [f'{i}.json' for i in range(1, len(file_links) + 1)]\n",
    "\n",
    "# Crear la carpeta ArchivosIgnore si no existe\n",
    "output_dir = 'ArchivosIgnore'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Inicializar una lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y leer cada archivo JSON\n",
    "for file_link, file_name in zip(file_links, file_names):\n",
    "    try:\n",
    "        # Ruta completa del archivo\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        # Verificar si el archivo ya está descargado\n",
    "        if not os.path.exists(file_path):\n",
    "            # Obtener el ID del archivo desde el enlace\n",
    "            file_id = file_link.split('/d/')[1].split('/')[0]\n",
    "            download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "            \n",
    "            # Descargar el archivo\n",
    "            gdown.download(download_url, file_path, quiet=False)\n",
    "        \n",
    "        # Leer el archivo JSON en un DataFrame\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            first_char = file.read(1)\n",
    "            if not first_char:\n",
    "                raise ValueError(f\"El archivo {file_name} está vacío.\")\n",
    "            file.seek(0)\n",
    "            df = pd.read_json(file, lines=True)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo {file_name}: {e}\")\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_metadataGoog = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrar por estado California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraer el estado de la dirección\n",
    "df_metadataGoog['estado'] = df_metadataGoog['address'].str.extract(r', ([A-Z]{2}) \\d{5}')\n",
    "#filtro los datos de California, para liberar espacio\n",
    "df_metadatosCA = df_metadataGoog[df_metadataGoog['estado'] == 'CA']\n",
    "#elimino el dataframe que tiene los metadatos de todos los estados, para liberar memoria\n",
    "del df_metadataGoog\n",
    "#reseteo indice\n",
    "df_metadatosCA.reset_index(inplace=True)\n",
    "df_metadatosCA.drop('index', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadatosCA.drop_duplicates(subset=['gmap_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armado de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solo para usar cuando se quiere importar el archivo\n",
    "#df_metadatosCA=pd.read_parquet('Archivos/metadatosCA.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer Ciudad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer la ciudad\n",
    "def extract_city(address):\n",
    "    match = re.search(r',\\s*([^,]+),\\s*[A-Z]{2}\\s*\\d{5}', address)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# Aplicar la función a la columna 'address' y crear la columna 'city'\n",
    "df_metadatosCA['city'] = df_metadatosCA['address'].apply(extract_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para asegurarse de que el tiempo esté en el formato \"HH:MMAM/PM\"\n",
    "def ensure_time_format(time_str):\n",
    "    if '–' in time_str:\n",
    "        parts = time_str.split('–')\n",
    "        parts = [ensure_time_format(part) for part in parts]\n",
    "        return '–'.join(parts)\n",
    "    try:\n",
    "        if ':' not in time_str:\n",
    "            time_obj = pd.to_datetime(time_str, format='%I%p', errors='coerce')\n",
    "        else:\n",
    "            time_obj = pd.to_datetime(time_str, format='%I:%M%p', errors='coerce')\n",
    "        if time_obj is not pd.NaT:\n",
    "            return time_obj.strftime('%I:%M%p')\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting time: {time_str}, error: {e}\")\n",
    "    return None\n",
    "\n",
    "# Función para calcular las horas diurnas (8 AM - 10 PM)\n",
    "def calculate_day_hours(hours_array):\n",
    "    total_day_hours = 0\n",
    "    if hours_array is not None and isinstance(hours_array, np.ndarray):\n",
    "        for entry in hours_array:\n",
    "            if isinstance(entry, np.ndarray) and len(entry) == 2:\n",
    "                day, hours = entry\n",
    "                if 'Closed' in hours:\n",
    "                    continue\n",
    "                if '–' in hours:\n",
    "                    open_time, close_time = hours.split('–')\n",
    "                    open_time = ensure_time_format(open_time)\n",
    "                    close_time = ensure_time_format(close_time)\n",
    "                    \n",
    "                    if open_time and close_time:\n",
    "                        open_hour = pd.to_datetime(open_time, format='%I:%M%p').hour\n",
    "                        close_hour = pd.to_datetime(close_time, format='%I:%M%p').hour\n",
    "\n",
    "                        if open_hour < 8:\n",
    "                            open_hour = 8\n",
    "                        if close_hour > 22:\n",
    "                            close_hour = 22\n",
    "\n",
    "                        if close_hour < open_hour:\n",
    "                            close_hour += 24  # Para manejar el cambio de día\n",
    "\n",
    "                        total_day_hours += max(0, close_hour - open_hour)\n",
    "    return total_day_hours\n",
    "\n",
    "# Función para calcular las horas nocturnas (10 PM - 8 AM)\n",
    "def calculate_night_hours(hours_array):\n",
    "    total_night_hours = 0\n",
    "    if hours_array is not None and isinstance(hours_array, np.ndarray):\n",
    "        for entry in hours_array:\n",
    "            if isinstance(entry, np.ndarray) and len(entry) == 2:\n",
    "                day, hours = entry\n",
    "                if 'Closed' in hours:\n",
    "                    continue\n",
    "                if '–' in hours:\n",
    "                    open_time, close_time = hours.split('–')\n",
    "                    open_time = ensure_time_format(open_time)\n",
    "                    close_time = ensure_time_format(close_time)\n",
    "\n",
    "                    if open_time and close_time:\n",
    "                        open_hour = pd.to_datetime(open_time, format='%I:%M%p').hour\n",
    "                        close_hour = pd.to_datetime(close_time, format='%I:%M%p').hour\n",
    "\n",
    "                        if close_hour < open_hour:\n",
    "                            close_hour += 24  # Para manejar el cambio de día\n",
    "\n",
    "                        night_hours = 0\n",
    "                        if open_hour < 8:\n",
    "                            night_hours += min(8, close_hour) - open_hour\n",
    "                        if close_hour > 22:\n",
    "                            night_hours += close_hour - 22\n",
    "\n",
    "                        total_night_hours += max(0, night_hours)\n",
    "    return total_night_hours\n",
    "\n",
    "# Aplicar las funciones al DataFrame\n",
    "df_metadatosCA['Hours_day'] = df_metadatosCA['hours'].apply(calculate_day_hours)\n",
    "df_metadatosCA['Hours_night'] = df_metadatosCA['hours'].apply(calculate_night_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expandir las listas en filas individuales\n",
    "categorias_expandidas = df_metadatosCA['category'].explode()\n",
    "\n",
    "# Contar las ocurrencias de cada categoría\n",
    "conteo_categorias = categorias_expandidas.value_counts()\n",
    "\n",
    "# Eliminar la serie que ya no se usa\n",
    "del categorias_expandidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteo_categorias.to_csv('Archivos/categoriasCA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explotar columna MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer y expandir los diccionarios en nuevas columnas\n",
    "def expand_misc_column(misc_dict):\n",
    "    if pd.isna(misc_dict):\n",
    "        return pd.Series()\n",
    "    expanded = {}\n",
    "    for key, value in misc_dict.items():\n",
    "        if value is not None and isinstance(value, np.ndarray):\n",
    "            expanded[key] = ', '.join(value)\n",
    "        else:\n",
    "            expanded[key] = value\n",
    "    return pd.Series(expanded)\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "expanded_df = df_metadatosCA['MISC'].apply(expand_misc_column)\n",
    "\n",
    "# Unir el DataFrame original con el DataFrame expandido\n",
    "df_metadatosCA = pd.concat([df_metadatosCA, expanded_df], axis=1)\n",
    "\n",
    "#Eliminar la columna MISC que ya no se usa\n",
    "df_metadatosCA.drop(columns='MISC', inplace=True)\n",
    "\n",
    "del expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir ciudad\n",
    "ciudadelegida='Los Angeles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listado de negocios de la ciudad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro el listado\n",
    "negocios=df_metadatosCA['gmap_id'][df_metadatosCA['city'] == ciudadelegida]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo exporto a un csv\n",
    "negocios.to_csv('Archivos/negociosciudad.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir ciudad\n",
    "ciudadelegida='Los Angeles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar el dataframe a exportar\n",
    "df_ML = df_metadatosCA.loc[df_metadatosCA['city'] == ciudadelegida, \n",
    "                           ['address', 'gmap_id', 'latitude', 'longitude',\n",
    "                            'category', 'avg_rating', 'num_of_reviews', 'Hours_day', 'Hours_night']]\n",
    "\n",
    "# Exportar el dataframe\n",
    "df_ML.to_csv('Archivos/metadatos_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Service options\n",
       "[In-store shopping, Delivery]                                                                             13305\n",
       "[In-store shopping]                                                                                       10081\n",
       "[Delivery]                                                                                                 9147\n",
       "[Takeout, Delivery]                                                                                        4511\n",
       "[In-store pickup, In-store shopping]                                                                       3107\n",
       "                                                                                                          ...  \n",
       "[No-contact delivery, Delivery, Takeout, Same-day delivery, In-store shopping, Dine-in]                       1\n",
       "[Outdoor seating, No-contact delivery, Delivery, In-store pickup, In-store shopping, Takeout, Dine-in]        1\n",
       "[No-contact delivery, Delivery, In-store pickup, Takeout, Dine-in, Same-day delivery]                         1\n",
       "[Online classes, Onsite services, Delivery]                                                                   1\n",
       "[Curbside pickup, In-store pickup, Onsite services]                                                           1\n",
       "Name: count, Length: 658, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadatosCA['Service options'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadatosCA.drop(columns=['name', 'description', 'hours', 'state', 'relative_results', 'From the business'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardo el archivo parquet, para poder importarlo si es necesario\n",
    "df_metadatosCA.to_parquet('Archivos/metadatosCA.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews Estados - Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs de los archivos de Google Drive\n",
    "file_links = [\n",
    "    'https://drive.google.com/file/d/13JlGdagtTp4SrUIXu5osayX0f-vmeMz6',\n",
    "    'https://drive.google.com/file/d/1PIruhKSA5gEwk93-jwKdlG_vtwJmBHWV', \n",
    "    'https://drive.google.com/file/d/1JVSi-345m8nt52m2_MPkLULZexbvZUAV', \n",
    "    'https://drive.google.com/file/d/1vYYCtcNcfdRzQpEskb8x-8npZUHj2XY-', \n",
    "    'https://drive.google.com/file/d/1nCyVnhNpfphd26ye3lj9UsWvPTEhik6b', \n",
    "    'https://drive.google.com/file/d/12PR9jUiZLYvjw6BZjwlexgsWmJlMOajN',\n",
    "    'https://drive.google.com/file/d/1Oq1UdTmQ4xFgkaFdx09JXJQ1_pnIk-il', \n",
    "    'https://drive.google.com/file/d/1UwzEftWrssj8Vt0BAf_W9L_TVDGa9JD9', \n",
    "    'https://drive.google.com/file/d/1KsXni6or_cPKovgUaRI_3G4-mRXfqgog', \n",
    "    'https://drive.google.com/file/d/1fK2kTLDqlUcDt6bKa20W5LvOmrfemDrg', \n",
    "    'https://drive.google.com/file/d/1rMz_y1cqa8IBwv1K6K34fAXB2qoRjmEG', \n",
    "    'https://drive.google.com/file/d/1t59IfitryIsy8-F9NL9J6M75UElQO0i9',\n",
    "    'https://drive.google.com/file/d/17VtmF8701j3Tk-tdHeRrXDzj32UyWFVh',\n",
    "    'https://drive.google.com/file/d/1zoN6XJV220ofRKVlM8DP--FriL_OcZEP',\n",
    "    'https://drive.google.com/file/d/1HUVCM9uOrXhoOzoSD9NqhHJ1PHrLEhBC',\n",
    "    'https://drive.google.com/file/d/1sqp0YG4OHVUoA0gWrgwg1wXpdOlF5RfD',\n",
    "    'https://drive.google.com/file/d/1SPDbJPTxKV1QqMcRNsHIhV7EZBLtRCWf',\n",
    "    'https://drive.google.com/file/d/1_Ik1uLilfLe0MEb1Gia-t9SpE1Wwdwnm'\n",
    "]\n",
    "\n",
    "# Nombres de los archivos locales (presumiendo que siguen el patrón 1.json, 2.json, ..., 11.json)\n",
    "file_names = [f'ArchivosIgnore/{i}.json' for i in range(1, len(file_links) + 1)]\n",
    "\n",
    "# Inicializar una lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y leer cada archivo JSON si no está descargado previamente\n",
    "for file_link, file_name in zip(file_links, file_names):\n",
    "    try:\n",
    "        # Verificar si el archivo ya está descargado\n",
    "        if not os.path.exists(file_name):\n",
    "            # Obtener el ID del archivo desde el enlace\n",
    "            file_id = file_link.split('/d/')[1].split('/')[0]\n",
    "            download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "            \n",
    "            # Descargar el archivo\n",
    "            gdown.download(download_url, file_name, quiet=False)\n",
    "            \n",
    "            # Verificar si el archivo descargado es un JSON válido\n",
    "            with open(file_name, 'r', encoding='utf-8') as file:\n",
    "                first_char = file.read(1)\n",
    "                if not first_char:\n",
    "                    raise ValueError(f\"El archivo {file_name} está vacío.\")\n",
    "                file.seek(0)\n",
    "            \n",
    "        # Leer el archivo JSON en un DataFrame\n",
    "        df = pd.read_json(file_name, lines=True)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_reviewsGoogle = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del file_link\n",
    "del file_name\n",
    "del file_names\n",
    "del file_links\n",
    "del first_char\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espacio que ocupan\n",
    "Carpeta: 763 Mb (3,8 segundos en importar para una lista, 48,44 segundos para pasarlo a dataframe)\n",
    "Dataframe: 164,8 Mb\n",
    "CSV: 545 Mbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewsGoogle.drop_duplicates(subset=['user_id', 'time', 'gmap_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si tiene texto\n",
    "df_reviewsGoogle['has_text'] = df_reviewsGoogle['text'].apply(lambda x: 1 if isinstance(x, str) and len(x.strip()) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cantidad de fotos\n",
    "df_reviewsGoogle['num_pics'] = df_reviewsGoogle['pics'].apply(lambda x: len(x) if isinstance(x, list) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si tiene respuesta\n",
    "df_reviewsGoogle['has_resp'] = df_reviewsGoogle['resp'].apply(lambda x: 1 if isinstance(x, dict) and len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro por los negocios de la ciudad\n",
    "df_reviewsGoogle_ML = df_reviewsGoogle[df_reviewsGoogle['gmap_id'].isin(negocios)][['user_id', 'time', 'rating', 'gmap_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esportar a un csv\n",
    "df_reviewsGoogle_ML.to_csv('Archivos/reviewsGoogle_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar columnas innecesarias\n",
    "df_reviewsGoogle.drop(columns=['name', 'text', 'pics', 'resp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esportar a un parquet\n",
    "df_reviewsGoogle.to_parquet('ArchivosIgnore/ReviewsGoogle.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminacion de dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_reviewsGoogle\n",
    "del df_reviewsGoogle_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business - YELP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los archivos desde la nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'ArchivosIgnore/business.pkl' cargado en el DataFrame correctamente.\n"
     ]
    }
   ],
   "source": [
    "# ID del archivo de Google Drive\n",
    "file_id = '1byFtzpZXopdCN-XYmMHMpZqzgAqfQBBu'\n",
    "\n",
    "# Construir la URL de descarga\n",
    "download_url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Nombre del archivo local\n",
    "file_path = 'ArchivosIgnore/business.pkl'\n",
    "\n",
    "# Verificar si el archivo ya está descargado\n",
    "if not os.path.exists(file_path):\n",
    "    try:\n",
    "        # Descargar el archivo usando gdown\n",
    "        gdown.download(download_url, file_path, quiet=False)\n",
    "        print(f\"Archivo '{file_path}' descargado correctamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar el archivo: {e}\")\n",
    "\n",
    "# Cargar el archivo pickle en un DataFrame de pandas si existe\n",
    "if os.path.exists(file_path):\n",
    "    try:\n",
    "        df_business = pd.read_pickle(file_path)\n",
    "        print(f\"Archivo '{file_path}' cargado en el DataFrame correctamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el archivo en el DataFrame: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"El archivo '{file_path}' no está disponible para cargar en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminacion de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
       "       'attributes', 'categories', 'hours', 'business_id', 'name', 'address',\n",
       "       'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars',\n",
       "       'review_count', 'is_open', 'attributes', 'categories', 'hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business.drop_duplicates(subset=['business_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renombro y saco columnas\n",
    "df_business.columns=['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
    "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
    "       'attributes', 'categories', 'hours', 'business_id2', 'name2', 'address2',\n",
    "       'city2', 'state2', 'postal_code2', 'latitude2', 'longitude2', 'stars2',\n",
    "       'review_count2', 'is_open2', 'attributes2', 'categories2', 'hours2']\n",
    "\n",
    "df_business.drop(columns=['business_id2', 'name2', 'address2',\n",
    "       'city2', 'state2', 'postal_code2', 'latitude2', 'longitude2', 'stars2',\n",
    "       'review_count2', 'is_open2', 'attributes2', 'categories2', 'hours2'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado por california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego, aplica el filtro para las empresas en California (por código postal)\n",
    "df_business_CA = df_business[(df_business['postal_code'] >= '90000') & (df_business['postal_code'] <= '96612')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado por Los Angeles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_LA = df_business_CA[(df_business_CA['postal_code'] >= '90000') & (df_business_CA['postal_code'] <= '91609')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de los Datos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina valores nulos en las columnas attributes y hours\n",
    "df_business_CA= df_business_CA.dropna(subset=['attributes', 'hours'])\n",
    "\n",
    "# Modificación del tipo  de datos en las columnas 'latitude','longitud','stars','review_count','is-open'\n",
    "\n",
    "df_business_CA['latitude'] = pd.to_numeric(df_business_CA['latitude'], errors='coerce')\n",
    "df_business_CA['longitude'] = pd.to_numeric(df_business_CA['longitude'], errors='coerce')\n",
    "df_business_CA['stars'] = pd.to_numeric(df_business_CA['stars'], errors='coerce')\n",
    "df_business_CA['review_count'] = pd.to_numeric(df_business_CA['review_count'], errors='coerce')\n",
    "df_business_CA['is_open'] = pd.to_numeric(df_business_CA['is_open'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminacion de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_CA.drop(columns=['is_open'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino columnas que no se usan del DF dpara ML\n",
    "df_business_LA.drop(columns=['state', 'postal_code','is_open','hours'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardo el archivo parquet, para poder importarlo si es necesario\n",
    "df_business_CA.to_parquet('Archivos/business_CA_Yelp.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv para ML\n",
    "df_business_LA.to_csv('Archivos/business_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listado de negocios de YELP\n",
    "businessCA=df_business_CA['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessCA.to_csv('Archivos/yelpCA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessML=df_business_LA['business_id']\n",
    "businessML.to_csv('Archivos/BusinesslistYELPML.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review - YELP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al descargar el archivo: Failed to retrieve file url:\n",
      "\n",
      "\tToo many users have viewed or downloaded this file recently. Please\n",
      "\ttry accessing the file again later. If the file you are trying to\n",
      "\taccess is particularly large or is shared with many people, it may\n",
      "\ttake up to 24 hours to be able to view or download the file. If you\n",
      "\tstill can't access a file after 24 hours, contact your domain\n",
      "\tadministrator.\n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\thttps://drive.google.com/uc?id=1mwNNdOMSNty6WumYdH9FJNJZJYQ6oD1c\n",
      "\n",
      "but Gdown can't. Please check connections and permissions.\n",
      "Error al procesar el archivo JSON: File ArchivosIgnore/data.json does not exist\n"
     ]
    }
   ],
   "source": [
    "# ID del archivo de Google Drive\n",
    "file_id = '1mwNNdOMSNty6WumYdH9FJNJZJYQ6oD1c'\n",
    "\n",
    "# URL de descarga directa desde Google Drive\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Nombre del archivo descargado y ruta de salida\n",
    "output = 'ArchivosIgnore/data.json'\n",
    "file_path = output\n",
    "\n",
    "# Verificar si el archivo ya está descargado\n",
    "if not os.path.exists(file_path):\n",
    "    try:\n",
    "        # Descargar el archivo\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        print(f\"Archivo '{output}' descargado correctamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar el archivo: {e}\")\n",
    "\n",
    "# Procesar el archivo JSON en chunks y guardar en un DataFrame final\n",
    "try:\n",
    "    # Definir el tamaño del chunk (número de líneas por chunk)\n",
    "    chunk_size = 1000\n",
    "\n",
    "    # Lista para almacenar los DataFrames procesados\n",
    "    results = []\n",
    "\n",
    "    # Leer el archivo JSON en chunks\n",
    "    chunks = pd.read_json(file_path, lines=True, chunksize=chunk_size)\n",
    "\n",
    "    # Procesar cada chunk por separado\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Ejemplo de procesamiento: mostrar las primeras filas del chunk\n",
    "        print(f\"Procesando chunk {i + 1}\")\n",
    "        print(chunk.head())\n",
    "\n",
    "        # Guardar resultados intermedios en una lista\n",
    "        results.append(chunk)\n",
    "\n",
    "        # Liberar memoria si no necesitas almacenar los chunks completos\n",
    "        del chunk\n",
    "\n",
    "    # Combinar todos los chunks procesados en un solo DataFrame final\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    print(\"Procesamiento completo. DataFrame final creado.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al procesar el archivo JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros de dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessCA=pd.read_csv('Archivos/yelpCA.csv')\n",
    "businessML=pd.read_csv('Archivos/businesslistYELPML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reviewYELP\u001b[38;5;241m=\u001b[39m\u001b[43mfinal_df\u001b[49m[final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusiness_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(businessCA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusiness_id\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "reviewYELP=final_df[final_df['business_id'].isin(businessCA['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewYELPML=final_df[final_df['business_id'].isin(businessML['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewYELPML.to_csv('Archivos/ReviewsYELP_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewYELP.to_parquet('Archivos/ReviewYELP.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER - YELP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al descargar el archivo: Failed to retrieve file url:\n",
      "\n",
      "\tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
      "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\thttps://drive.google.com/uc?id=1TT4ARRIV6i2fO1b5yb0aSUkjhxMb9u6g\n",
      "\n",
      "but Gdown can't. Please check connections and permissions.\n",
      "El archivo 'user.parquet' no está disponible para cargar en el DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# ID del archivo de Google Drive\n",
    "file_id = '1TT4ARRIV6i2fO1b5yb0aSUkjhxMb9u6g'\n",
    "\n",
    "# URL de descarga directa desde Google Drive\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Nombre del archivo descargado\n",
    "output = 'user.parquet'\n",
    "\n",
    "# Verificar si el archivo ya está descargado\n",
    "if not os.path.exists(output):\n",
    "    try:\n",
    "        # Descargar el archivo si no está presente localmente\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        print(f\"Archivo '{output}' descargado correctamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar el archivo: {e}\")\n",
    "\n",
    "# Leer el archivo Parquet en un DataFrame si existe\n",
    "if os.path.exists(output):\n",
    "    try:\n",
    "        df = pd.read_parquet(output)\n",
    "        print(f\"Archivo '{output}' cargado en el DataFrame correctamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el archivo en el DataFrame: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"El archivo '{output}' no está disponible para cargar en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro ciudad elegida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se importa el archivo usado\n",
    "df_rev_YELP_ML=pd.read_csv('Archivos/ReviewsYELP_ML.csv')\n",
    "#se toman los valores de userid\n",
    "listado=df_rev_YELP_ML['user_id'].unique()\n",
    "#eliminar df\n",
    "del df_rev_YELP_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular valores nulos y porcentajes\n",
    "valores_nulos = df.isnull().sum()\n",
    "# Contar las ocurrencias de cada fila duplicada\n",
    "duplicate_counts = df[df.duplicated()].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir el DataFrame como un archivo Parquet\n",
    "filtered_reviews_ca.to_parquet('Archivos/user_ca.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga (LOAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivos para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_ML=df[df['user_id'].isin(listado)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_ML.drop(columns=['compliment_hot',\n",
    "       'compliment_more', 'compliment_profile', 'compliment_cute',\n",
    "       'compliment_list', 'compliment_note', 'compliment_plain',\n",
    "       'compliment_cool', 'compliment_funny', 'compliment_writer',\n",
    "       'compliment_photos'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_ML.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_ML.to_csv('Archivos/user_ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear ETL local como script de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ETL.ipynb to script\n",
      "[NbConvertApp] Writing 23062 bytes to ETL.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script ETL.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCP Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Programacion\\1 - Henrry\\Data Science\\CLASES - DATA\\PROYECTO FINAL\\PFH_Google_Yelp\\cloud_up.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError al subir el archivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Llamada a la función para subir tu archivo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43msubir_archivo_gcs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetadatosCA.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mArchivos/metadatosCA.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Asumiendo que el archivo está en el mismo directorio que el script\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Programacion\\1 - Henrry\\Data Science\\CLASES - DATA\\PROYECTO FINAL\\PFH_Google_Yelp\\cloud_up.py:17\u001b[0m, in \u001b[0;36msubir_archivo_gcs\u001b[1;34m(nombre_archivo, ruta_archivo, nombre_bucket)\u001b[0m\n\u001b[0;32m     14\u001b[0m     blob \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mblob(nombre_archivo)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Aumentamos el timeout a 10 minutos para archivos grandes o conexiones lentas\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_from_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_archivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArchivo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_archivo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m subido a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_bucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m exitosamente.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:2947\u001b[0m, in \u001b[0;36mBlob.upload_from_filename\u001b[1;34m(self, filename, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[0;32m   2834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_from_filename\u001b[39m(\n\u001b[0;32m   2835\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2836\u001b[0m     filename,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2847\u001b[0m     retry\u001b[38;5;241m=\u001b[39mDEFAULT_RETRY_IF_GENERATION_SPECIFIED,\n\u001b[0;32m   2848\u001b[0m ):\n\u001b[0;32m   2849\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Upload this blob's contents from the content of a named file.\u001b[39;00m\n\u001b[0;32m   2850\u001b[0m \n\u001b[0;32m   2851\u001b[0m \u001b[38;5;124;03m    The content type of the upload will be determined in order\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2944\u001b[0m \u001b[38;5;124;03m        such as delays and deadlines are respected.\u001b[39;00m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2947\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_filename_and_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredefined_acl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_acl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2960\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:2826\u001b[0m, in \u001b[0;36mBlob._handle_filename_and_upload\u001b[1;34m(self, filename, content_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[0;32m   2825\u001b[0m     total_bytes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfstat(file_obj\u001b[38;5;241m.\u001b[39mfileno())\u001b[38;5;241m.\u001b[39mst_size\n\u001b[1;32m-> 2826\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_and_do_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:2643\u001b[0m, in \u001b[0;36mBlob._prep_and_do_upload\u001b[1;34m(self, file_obj, rewind, size, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[0;32m   2640\u001b[0m predefined_acl \u001b[38;5;241m=\u001b[39m ACL\u001b[38;5;241m.\u001b[39mvalidate_predefined(predefined_acl)\n\u001b[0;32m   2642\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2643\u001b[0m     created_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2647\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredefined_acl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(created_json)\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:2466\u001b[0m, in \u001b[0;36mBlob._do_upload\u001b[1;34m(self, client, stream, content_type, size, num_retries, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[0;32m   2449\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_multipart_upload(\n\u001b[0;32m   2450\u001b[0m         client,\n\u001b[0;32m   2451\u001b[0m         stream,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2463\u001b[0m         command\u001b[38;5;241m=\u001b[39mcommand,\n\u001b[0;32m   2464\u001b[0m     )\n\u001b[0;32m   2465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2466\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_resumable_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredefined_acl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2481\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\storage\\blob.py:2302\u001b[0m, in \u001b[0;36mBlob._do_resumable_upload\u001b[1;34m(self, client, stream, content_type, size, num_retries, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m upload\u001b[38;5;241m.\u001b[39mfinished:\n\u001b[0;32m   2301\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2302\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mupload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransmit_next_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2303\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mDataCorruption:\n\u001b[0;32m   2304\u001b[0m         \u001b[38;5;66;03m# Attempt to delete the corrupted object.\u001b[39;00m\n\u001b[0;32m   2305\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete()\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\requests\\upload.py:515\u001b[0m, in \u001b[0;36mResumableUpload.transmit_next_chunk\u001b[1;34m(self, transport, timeout)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_resumable_response(result, \u001b[38;5;28mlen\u001b[39m(payload))\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\requests\\_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[1;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[0;32m    153\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    157\u001b[0m     error \u001b[38;5;241m=\u001b[39m e  \u001b[38;5;66;03m# Fall through to retry, if there are retries left.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\resumable_media\\requests\\upload.py:507\u001b[0m, in \u001b[0;36mResumableUpload.transmit_next_chunk.<locals>.retriable_request\u001b[1;34m()\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretriable_request\u001b[39m():\n\u001b[1;32m--> 507\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_resumable_response(result, \u001b[38;5;28mlen\u001b[39m(payload))\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\auth\\transport\\requests.py:541\u001b[0m, in \u001b[0;36mAuthorizedSession.request\u001b[1;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[38;5;28;01mas\u001b[39;00m guard:\n\u001b[1;32m--> 541\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAuthorizedSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    549\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:414\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%x\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(chunk), chunk))\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Regardless of whether we have a body or not, if we're in\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# chunked mode we want to send an explicit empty chunk.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunked:\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1045\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1043\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.send\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, data)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable):\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1212\u001b[0m, in \u001b[0;36mSSLSocket.sendall\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1210\u001b[0m         amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(byte_view)\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m count \u001b[38;5;241m<\u001b[39m amount:\n\u001b[1;32m-> 1212\u001b[0m             v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m             count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\londe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1181\u001b[0m, in \u001b[0;36mSSLSocket.send\u001b[1;34m(self, data, flags)\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1180\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(data, flags)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run cloud_up.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
